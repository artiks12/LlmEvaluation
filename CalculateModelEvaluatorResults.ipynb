{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'instructions/'\n",
    "file = 'ModelInstructions.json'\n",
    "model = 'gemini-2.0-flash'\n",
    "with open(path+file, encoding='utf-8') as f:\n",
    "    instructions = json.load(f)\n",
    "rag_ids = [str(item['id']) for item in instructions if item['rag_prompt'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateScore(numbers, method='avg'):\n",
    "    if type(numbers) == dict:\n",
    "        values = list(numbers.values())\n",
    "    else:\n",
    "        values = numbers\n",
    "    count = len(list(values[0]))\n",
    "    if all([len(group) == count for group in values]):\n",
    "        if type(method) == int:\n",
    "            intermediate = [ [val for val in group][method-1] for group in values]\n",
    "        if method == 'avg':\n",
    "            intermediate = [ sum([val for val in group])/len(group) for group in values]\n",
    "        if method == 'max':\n",
    "            intermediate = [ max([val for val in group]) for group in values]\n",
    "        if method == 'min':\n",
    "            intermediate = [ min([val for val in group]) for group in values]\n",
    "        if method == 'random':\n",
    "            intermediate = [ group[random.randint(0,count-1)] for group in values]\n",
    "\n",
    "        return round(sum(intermediate)/len(intermediate),4)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckResults(values):\n",
    "    x, y = None, None\n",
    "    try:\n",
    "        for g, vals in values.items():\n",
    "            x = g\n",
    "            for v in range(len(vals)):\n",
    "                y = v\n",
    "                float(vals[v])\n",
    "        return True\n",
    "    except:\n",
    "        print(x,y)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def FixValues(values, letter = 'L'):\n",
    "    result = {}\n",
    "    for g, vals in values.items():\n",
    "        result[g] = []\n",
    "        for v in range(len(vals)):\n",
    "            try:\n",
    "                cleaned_text = vals[v].rstrip(' \\n.*')\n",
    "                match = re.search(r'(-?\\d+(?:\\.\\d+)?)\\**$', cleaned_text)\n",
    "                if match:\n",
    "                    val = match.group(1).strip('*')\n",
    "                    result[g].append(float(val))\n",
    "                else:\n",
    "                    print(f'No value at {g}!')\n",
    "            except:\n",
    "                print(f'Error at {g}!')\n",
    "            if len(result[g]) == 0: del result[g]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetIds(rag_ids,values):\n",
    "    return {k:v for k,v in values.items() if k in rag_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.0-flash_New_ChatbotEvaluateCustomRAG_RAG_results_EuroLLM-9B-Instruct-LatLeg-14.9K-F16.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateCustomRAG_RAG_results_EuroLLM-9B-Instruct-LatLeg-14.9K-F16.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateCustomRAG_RAG_results_EuroLLM-9B-Instruct-LatLeg-14.9K-F16.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateCustomRAG_RAG_results_EuroLLM-9B-Instruct-LatLeg-14.9K-Q4_K_M.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateCustomRAG_RAG_results_EuroLLM-9B-Instruct-LatLeg-14.9K-Q4_K_M.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateCustomRAG_RAG_results_EuroLLM-9B-Instruct-LatLeg-14.9K-Q4_K_M.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateCustomRAG_RAG_results_EuroLLM-9B-Instruct-LatLeg-32.4K-F16.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateCustomRAG_RAG_results_EuroLLM-9B-Instruct-LatLeg-32.4K-F16.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateCustomRAG_RAG_results_EuroLLM-9B-Instruct-LatLeg-32.4K-F16.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateCustomRAG_RAG_results_EuroLLM-9B-Instruct-LatLeg-32.4K-Q4_K_M.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateCustomRAG_RAG_results_EuroLLM-9B-Instruct-LatLeg-32.4K-Q4_K_M.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateCustomRAG_RAG_results_EuroLLM-9B-Instruct-LatLeg-32.4K-Q4_K_M.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateRAG_results_EuroLLM-9B-Instruct-LatLeg-14.9K-F16.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateRAG_results_EuroLLM-9B-Instruct-LatLeg-14.9K-F16.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateRAG_results_EuroLLM-9B-Instruct-LatLeg-14.9K-F16.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateRAG_results_EuroLLM-9B-Instruct-LatLeg-14.9K-Q4_K_M.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateRAG_results_EuroLLM-9B-Instruct-LatLeg-14.9K-Q4_K_M.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateRAG_results_EuroLLM-9B-Instruct-LatLeg-14.9K-Q4_K_M.json 90\n",
      "No value at 40.L!\n",
      "No value at 126.L!\n",
      "gemini-2.0-flash_New_ChatbotEvaluateRAG_results_EuroLLM-9B-Instruct-LatLeg-32.4K-F16.json 88\n",
      "No value at 40.L!\n",
      "No value at 126.L!\n",
      "gemini-2.0-flash_New_ChatbotEvaluateRAG_results_EuroLLM-9B-Instruct-LatLeg-32.4K-F16.json 90\n",
      "No value at 40.L!\n",
      "No value at 126.L!\n",
      "gemini-2.0-flash_New_ChatbotEvaluateRAG_results_EuroLLM-9B-Instruct-LatLeg-32.4K-F16.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateRAG_results_EuroLLM-9B-Instruct-LatLeg-32.4K-Q4_K_M.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateRAG_results_EuroLLM-9B-Instruct-LatLeg-32.4K-Q4_K_M.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateRAG_results_EuroLLM-9B-Instruct-LatLeg-32.4K-Q4_K_M.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateresults_EuroLLM-9B-Instruct-LatLeg-14.9K-F16.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateresults_EuroLLM-9B-Instruct-LatLeg-14.9K-F16.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateresults_EuroLLM-9B-Instruct-LatLeg-14.9K-F16.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateresults_EuroLLM-9B-Instruct-LatLeg-14.9K-Q4_K_M.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateresults_EuroLLM-9B-Instruct-LatLeg-14.9K-Q4_K_M.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateresults_EuroLLM-9B-Instruct-LatLeg-14.9K-Q4_K_M.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateresults_EuroLLM-9B-Instruct-LatLeg-32.4K-F16.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateresults_EuroLLM-9B-Instruct-LatLeg-32.4K-F16.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateresults_EuroLLM-9B-Instruct-LatLeg-32.4K-F16.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateresults_EuroLLM-9B-Instruct-LatLeg-32.4K-Q4_K_M.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateresults_EuroLLM-9B-Instruct-LatLeg-32.4K-Q4_K_M.json 90\n",
      "gemini-2.0-flash_New_ChatbotEvaluateresults_EuroLLM-9B-Instruct-LatLeg-32.4K-Q4_K_M.json 90\n"
     ]
    }
   ],
   "source": [
    "path = 'Scores/LlmEvaluatorAnswers/'\n",
    "\n",
    "files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "rag_evaluation = True\n",
    "\n",
    "for file in files:\n",
    "    fullPath = path + file\n",
    "    with open(path+file, encoding='utf-8') as f:\n",
    "        values = json.load(f)\n",
    "        if rag_evaluation: \n",
    "            values = GetIds(rag_ids,values)\n",
    "    print(file, len(values))\n",
    "    values = FixValues(values)\n",
    "    if CheckResults(values):\n",
    "        avg = CalculateScore(values)\n",
    "        result = {\n",
    "            'avg':avg\n",
    "        }\n",
    "        saveFile = f'RAG_scores_{file}' if rag_evaluation else f'scores_{file}'\n",
    "        with open(f'Scores/LlmEvaluatorScores/{saveFile}', 'wt', encoding='utf-8') as f:\n",
    "            json.dump(result, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
